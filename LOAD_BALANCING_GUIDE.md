# âš–ï¸ LOAD BALANCING Vá»šI NGINX - HÆ¯á»šNG DáºªN

**NgÃ y triá»ƒn khai**: 2025-01-27  
**Tráº¡ng thÃ¡i**: âœ… HoÃ n táº¥t

---

## ğŸ“‹ Tá»”NG QUAN

Há»‡ thá»‘ng Ä‘Ã£ Ä‘Æ°á»£c cáº¥u hÃ¬nh vá»›i:
- âœ… **Nginx Load Balancer** - PhÃ¢n phá»‘i requests
- âœ… **3 API Instances** - Xá»­ lÃ½ requests song song
- âœ… **Health Checks** - Tá»± Ä‘á»™ng loáº¡i bá» server khÃ´ng healthy
- âœ… **Rate Limiting** - Báº£o vá»‡ á»Ÿ táº§ng Nginx
- âœ… **High Availability** - KhÃ´ng cÃ³ single point of failure

---

## ğŸ—ï¸ KIáº¾N TRÃšC

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Client    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                    â”‚   Nginx     â”‚
                    â”‚ Load Balancerâ”‚
                    â””â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”˜
                       â”‚   â”‚   â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚              â”‚   â”‚   â”‚              â”‚
   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â–¼â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
   â”‚ API 1   â”‚   â”‚   API 2            â”‚   â”‚ API 3   â”‚
   â”‚ :3000   â”‚   â”‚   :3000            â”‚   â”‚ :3000   â”‚
   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
        â”‚              â”‚                       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚              â”‚              â”‚
   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
   â”‚PostgreSQLâ”‚   â”‚  Redis   â”‚   â”‚RabbitMQ â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ CÃCH Sá»¬ Dá»¤NG

### 1. Khá»Ÿi Ä‘á»™ng há»‡ thá»‘ng

```bash
# Build vÃ  start táº¥t cáº£ services
docker-compose -f docker-compose.prod.yml up -d --build

# Kiá»ƒm tra status
docker-compose -f docker-compose.prod.yml ps

# Xem logs
docker-compose -f docker-compose.prod.yml logs -f nginx
docker-compose -f docker-compose.prod.yml logs -f api1
```

### 2. Test Load Balancing

```bash
# Test vá»›i curl (sáº½ Ä‘Æ°á»£c phÃ¢n phá»‘i giá»¯a 3 instances)
for i in {1..10}; do
  curl http://localhost/api/products | jq '.items[0].name'
  echo ""
done

# Kiá»ƒm tra instance nÃ o xá»­ lÃ½ request
# (CÃ³ thá»ƒ thÃªm header X-Instance-ID trong response Ä‘á»ƒ debug)
```

### 3. Kiá»ƒm tra Health

```bash
# Health check qua Nginx
curl http://localhost/health

# Health check trá»±c tiáº¿p tá»« instance
curl http://localhost:3000/api/health  # Sáº½ khÃ´ng hoáº¡t Ä‘á»™ng vÃ¬ port khÃ´ng expose
```

---

## âš™ï¸ Cáº¤U HÃŒNH

### Nginx Configuration

File: `nginx/nginx.conf`

**Load Balancing Method:**
- **Round-robin** (máº·c Ä‘á»‹nh): PhÃ¢n phá»‘i requests Ä‘á»u giá»¯a cÃ¡c servers
- CÃ³ thá»ƒ thay Ä‘á»•i thÃ nh:
  - `least_conn`: Chá»n server cÃ³ Ã­t connections nháº¥t
  - `ip_hash`: Sticky session dá»±a trÃªn IP client

**Health Checks:**
- `max_fails=3`: Sau 3 láº§n fail, server sáº½ bá»‹ loáº¡i bá»
- `fail_timeout=30s`: Sau 30s, server sáº½ Ä‘Æ°á»£c thá»­ láº¡i

**Rate Limiting:**
- API endpoints: 100 requests/second
- Auth endpoints: 5 requests/second

### Docker Compose

File: `docker-compose.prod.yml`

**Services:**
- `nginx`: Load balancer (port 80)
- `api1`, `api2`, `api3`: 3 API instances
- `postgres`, `redis`, `rabbitmq`: Shared services

**Connection Pooling:**
Má»—i API instance cÃ³ `connection_limit=30` trong DATABASE_URL:
```
DATABASE_URL=...&connection_limit=30&pool_timeout=20
```

Tá»•ng cá»™ng: 3 instances Ã— 30 connections = **90 connections** (Ä‘á»§ cho 300+ concurrent users)

---

## ğŸ“Š HIá»†U NÄ‚NG

### TrÆ°á»›c khi cÃ³ Load Balancing:
- **1 instance**: ~100 concurrent users
- **Single point of failure**: Náº¿u instance down â†’ toÃ n bá»™ há»‡ thá»‘ng down

### Sau khi cÃ³ Load Balancing:
- **3 instances**: ~300 concurrent users
- **High availability**: Náº¿u 1 instance down â†’ 2 instances cÃ²n láº¡i váº«n hoáº¡t Ä‘á»™ng
- **Load distribution**: Requests Ä‘Æ°á»£c phÃ¢n phá»‘i Ä‘á»u
- **Zero downtime**: CÃ³ thá»ƒ restart tá»«ng instance mÃ  khÃ´ng áº£nh hÆ°á»Ÿng

---

## ğŸ”§ TÃ™Y CHá»ˆNH

### Thay Ä‘á»•i sá»‘ lÆ°á»£ng instances

Sá»­a `docker-compose.prod.yml`:

```yaml
# ThÃªm instance má»›i
api4:
  build: .
  container_name: shopsphere-api-4
  # ... (copy tá»« api3)
```

VÃ  cáº­p nháº­t `nginx.conf`:
```nginx
upstream backend {
    server api1:3000 max_fails=3 fail_timeout=30s;
    server api2:3000 max_fails=3 fail_timeout=30s;
    server api3:3000 max_fails=3 fail_timeout=30s;
    server api4:3000 max_fails=3 fail_timeout=30s;  # ThÃªm dÃ²ng nÃ y
}
```

### Thay Ä‘á»•i Load Balancing Method

Sá»­a `nginx.conf`:

```nginx
upstream backend {
    least_conn;  # ThÃªm dÃ²ng nÃ y
    server api1:3000 max_fails=3 fail_timeout=30s;
    # ...
}
```

Hoáº·c cho sticky sessions:
```nginx
upstream backend {
    ip_hash;  # Sticky session
    server api1:3000 max_fails=3 fail_timeout=30s;
    # ...
}
```

### Thay Ä‘á»•i Rate Limits

Sá»­a `nginx.conf`:

```nginx
# TÄƒng rate limit cho API
limit_req_zone $binary_remote_addr zone=api_limit:10m rate=200r/s;

# TÄƒng rate limit cho auth
limit_req_zone $binary_remote_addr zone=auth_limit:10m rate=10r/s;
```

---

## ğŸ§ª TESTING

### Test Load Distribution

```bash
# Script Ä‘á»ƒ test load distribution
for i in {1..100}; do
  curl -s http://localhost/api/products > /dev/null
  echo "Request $i completed"
done

# Monitor logs Ä‘á»ƒ xem requests Ä‘Æ°á»£c phÃ¢n phá»‘i
docker-compose -f docker-compose.prod.yml logs -f nginx | grep "api"
```

### Test High Availability

```bash
# Stop má»™t instance
docker-compose -f docker-compose.prod.yml stop api1

# Test - há»‡ thá»‘ng váº«n hoáº¡t Ä‘á»™ng vá»›i 2 instances cÃ²n láº¡i
curl http://localhost/api/products

# Start láº¡i instance
docker-compose -f docker-compose.prod.yml start api1
```

### Test Health Checks

```bash
# Stop má»™t instance
docker-compose -f docker-compose.prod.yml stop api2

# Nginx sáº½ tá»± Ä‘á»™ng loáº¡i bá» api2 khá»i load balancer
# Sau 30s, api2 sáº½ Ä‘Æ°á»£c thá»­ láº¡i khi start

# Start láº¡i
docker-compose -f docker-compose.prod.yml start api2
```

---

## ğŸ“ˆ MONITORING

### Nginx Logs

```bash
# Access logs
docker-compose -f docker-compose.prod.yml exec nginx tail -f /var/log/nginx/access.log

# Error logs
docker-compose -f docker-compose.prod.yml exec nginx tail -f /var/log/nginx/error.log
```

### API Instance Logs

```bash
# Logs cá»§a táº¥t cáº£ instances
docker-compose -f docker-compose.prod.yml logs -f api1 api2 api3

# Logs cá»§a má»™t instance cá»¥ thá»ƒ
docker-compose -f docker-compose.prod.yml logs -f api1
```

### Health Status

```bash
# Check health cá»§a táº¥t cáº£ services
docker-compose -f docker-compose.prod.yml ps

# Health check endpoint
curl http://localhost/health | jq
```

---

## âš ï¸ TROUBLESHOOTING

### Váº¥n Ä‘á»: Nginx khÃ´ng start

**NguyÃªn nhÃ¢n:**
- Cáº¥u hÃ¬nh nginx.conf sai
- Port 80 Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng

**Giáº£i phÃ¡p:**
```bash
# Kiá»ƒm tra cáº¥u hÃ¬nh
docker-compose -f docker-compose.prod.yml exec nginx nginx -t

# Kiá»ƒm tra port
sudo lsof -i :80

# Xem logs
docker-compose -f docker-compose.prod.yml logs nginx
```

### Váº¥n Ä‘á»: Requests khÃ´ng Ä‘Æ°á»£c phÃ¢n phá»‘i

**NguyÃªn nhÃ¢n:**
- API instances chÆ°a ready
- Health check fail

**Giáº£i phÃ¡p:**
```bash
# Kiá»ƒm tra API instances
docker-compose -f docker-compose.prod.yml ps api1 api2 api3

# Test health check
curl http://localhost/health

# Kiá»ƒm tra nginx upstream
docker-compose -f docker-compose.prod.yml exec nginx cat /etc/nginx/nginx.conf | grep upstream
```

### Váº¥n Ä‘á»: Rate limiting quÃ¡ strict

**Giáº£i phÃ¡p:**
- TÄƒng rate limit trong `nginx.conf`
- Hoáº·c whitelist IP trong nginx config

---

## ğŸ¯ BEST PRACTICES

### 1. Health Checks
- âœ… Äáº£m báº£o health check endpoint hoáº¡t Ä‘á»™ng Ä‘Ãºng
- âœ… Cáº¥u hÃ¬nh `max_fails` vÃ  `fail_timeout` phÃ¹ há»£p

### 2. Connection Pooling
- âœ… Má»—i instance cÃ³ connection pool riÃªng
- âœ… Tá»•ng connections khÃ´ng vÆ°á»£t quÃ¡ database limit

### 3. Monitoring
- âœ… Monitor logs cá»§a táº¥t cáº£ instances
- âœ… Setup alerting khi instance down

### 4. Scaling
- âœ… Báº¯t Ä‘áº§u vá»›i 2-3 instances
- âœ… Scale dáº§n dáº§n dá»±a trÃªn traffic

---

## ğŸ“ FILES ÄÃƒ Táº O

1. âœ… `nginx/nginx.conf` - Cáº¥u hÃ¬nh Nginx load balancer
2. âœ… `docker-compose.prod.yml` - Updated vá»›i Nginx vÃ  multiple instances
3. âœ… `LOAD_BALANCING_GUIDE.md` - TÃ i liá»‡u nÃ y

---

## âœ… CHECKLIST

- [x] Nginx load balancer configuration
- [x] Multiple API instances (3 instances)
- [x] Health checks cho backend servers
- [x] Rate limiting á»Ÿ táº§ng Nginx
- [x] Connection pooling cho má»—i instance
- [x] High availability setup
- [x] Docker Compose configuration
- [x] Documentation

---

## ğŸš€ NEXT STEPS

Sau khi cÃ³ Load Balancing, báº¡n cÃ³ thá»ƒ:
1. âœ… Scale lÃªn nhiá»u instances hÆ¡n khi cáº§n
2. âœ… Setup SSL/TLS vá»›i Let's Encrypt
3. âœ… Implement session stickiness náº¿u cáº§n
4. âœ… Setup monitoring vá»›i Prometheus
5. âœ… Implement blue-green deployment

---

**Cáº­p nháº­t láº§n cuá»‘i**: 2025-01-27


